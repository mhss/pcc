Segundo projeto de PCC

Grupo:
Mário Henrique Santos da Silva (mhss)
	Árvore de sufixo
	Maior parte do front-end
	Scripts de teste
Israel Batista Freitas da Silva (ibfs)
	Array de sufixo
	Algoritmos de compressão
	Testes

Implementação

No modo de indexação, o conteúdo do arquivo é lido, e o conjunto de caracteres dele é determinado. Depois é construída a árvore de sufixo ou array de sufixo, dependendo da escolha do usuário. Então, em um arquivo são escritos o alfabeto e o índice do texto. O índice é representado por uma sequência de inteiros e caracteres, cada um escrito com fibonacci encoding. Então são escritos o tamanho e número de linhas do texto. Por último, o próprio texto é comprimido e escrito no arquivo. O algoritmo de compressão pode ser o LZ77 ou LZ78.
No modo de consulta, o arquivo de índice é aberto e são lidos o alfabeto do texto, o índice e o próprio texto, este último sendo descomprimido. O arquivo de índice informa o algoritmo de compressão usado e se o índice é uma árvore ou array de sufixo. Depois o programa percorre o texto pra determinar as posições de fim de cada linha. Então, para cada padrão a ser buscado, o programa encontra suas ocorrências no índice, determina as linhas às quais cada uma pertence e armazena elas num conjunto. Finalmente, cada linha com ocorrência de pelo menos um padrão é impressa, ou só a quantidade delas.

Algoritmos de Indexação
- Árvore de sufixo
O algoritmo usado para a construção foi o mostrado em aula, Ukkonen de 1995, com algumas alterações. Cada nó explícito da árvore é representado por um struct com um map que guarda as transições que saem daquele nó, indexadas pelo primeiro caractere da aresta. Os nós da árvore são guardados num array. Os suffix links são armazenados fora do struct, em um array alocado dinamicamente, pois são necessários somente durante a construção da árvore.
Os nós implícitos da árvore são representados por um struct com um nó explícito e um intervalo da string. Esse mesmo struct, por conveniência, representa as transições que saem de cada nó.
Para ser escrita num arquivo, a árvore é convertida numa sequência de inteiros e caracteres. O primeiro é a quantidade total de nós, e depois dele vêm, em sequência, as serializações de cada nó. A serialização de um nó consiste da quantidade de transações que saem dele, seguida pela sequência dessas transações. Cada transação é representada pelo índice do nó alvo e o intervalo da string que contém o rótulo da aresta. Cada valor é codificado no arquivo utilizando fibonacci encoding.
Para buscar um padrão, o programa procura o nó explícito mais baixo na árvore cujo rótulo tenha como prefixo o padrão buscado. Se ele existir, para cada folha da subárvore dele, o programa pega a altura e com ela determina a posição da ocorrência correspondente.

- Array de sufixo
O algoritmo utilizado para a construção do array de sufixo foi o Manber & Myers. São utilizados 4 arrays: um para o próprio array de sufixo, um para guardar o rank de cada sufixo, um para realizar o counting sort, e outro temporário que funciona como array de sufixo temporário e rank temporário. O rank inicial é dado pelo valor do caractere no Alfabeto.
As buscas são realizadas através do uso de duas buscas binárias: uma encontra o menor índice i no array de sufixo, a outra encontra o maior índice j no array de sufixo, tal qual, o prefixo de tamanho |P| do sufixo é igual ao padrão procurado, dado que P é o padrão procurado, e |P| representa o tamanho do padrão. O intervalo fechado de i à j possui todos os sufixos que possuem o padrão procurado como prefixo. Todos estes sufixos são processados e as linhas em que eles ocorrem são encontradas e reportadas pelo programa. O custo da busca é O(|P| * log(N)), onde N é o tamanho do texto.

Algoritmos de Compressão
- LZ77
O algoritmo LZ77 implementado foi a versão padrão do algoritmo, com tamanho de 1024 para cada array (dictionary e preview), e utilizando-se o algoritmo Aho-Corasick no preview, para encontrar o maior matching no array dictionary, em tempo linear no tamanho dos arrays.

- LZ78
O algoritmo LZ78, no momento de codificar o texto, utiliza uma estrutura de dados chamada Trie que funcionará como o dicionário necessário ao algoritmo. Esta Trie é implementada através da struct LzNode, declarada no mesmo arquivo do LZ78. No momento de descodificar o texto, é utilizado apenas um array de tamanho dinâmico (std::vector) para realização do processo.


Detalhes

Nos argumentos pra consulta, botamos o padrão depois do texto, pra ficar mais fácil fazer testes.
O programa só aceita textos com caracteres ASCII com valor de 0 a 255.
O consumo de memória durante a indexação tende a ser muito grande, chegando a 3GB para arquivos de mais de 25MB.
O programa só aceita padrões de no máximo 1000 caracteres.
Não conseguimos executar o programa corretamente com textos maiores que 35MB.

Testes

Os testes da ferramenta foram realizados em uma máquina virtual XUbuntu. A máquina hospedeira possui processador Intel Core i7 de 2.00 GHz, memória de 16GB, com SO Windows 8.1. Já a máquina virtual, possui 8 GB de memória e dois dos 4 núcleos de processamento.
Medimos o tempo gasto para indexar arquivos de texto, bem como o tamanho final dos arquivos gerados em comparação com os originais. Também medimos o tempo médio gasto com consultas de conjuntos de padrões nos índices dos textos, variando o tamanho dos padrões buscados. Cada consulta foi realizada três vezes para se obter uma média, e o desempenho foi comparado com o do programa grep ...

Dados

Os arquivos de texto utilizados nos testes estão disponíveis em http://pizzachili.dcc.uchile.cl/texts.html. Utilizamos até os primeiros 35MB de cada um, exceto o PITCHES, pelo seu formato inconveniente.
Os padrões utilizados nas consultas foram gerados aleatoriamente em conjuntos de 100, com tamanhos entre 2 e 10 e formados apenas por letras presentes nos arquivos de texto onde eram buscados. Já para os textos english e dblp.xml testamos também conjuntos de 20 cadeias frequentes neles.

Configuração

Só testamos a configuração que consideramos mais eficiente: árvore de sufixo com o algoritmo de compressão LZ78. Tanto a indexação como as consultas usando array de sufixo como índice mostraram um desempenho inferior ao da árvore de sufixo. Nós focamos na implementação neste último, e não utilizamos as técnicas mais eficientes com o array de sufixo.

Indexação

Para cada arquivo de texto, testamos a indexação dos primeiros 5, 10, ... 35 MB deles. Medimos o tempo de indexação e o tamanho dos arquivos gerados.

english
24.210000 49.690000 75.990000 102.420000 129.080000 157.760000 186.540000
106145741 231637987 355041296 491003716 620815992 737319871 858603287

dna
21.960000 45.070000 68.960000 93.180000 119.100000 144.990000 201.400000
108008118 226149970 347878776 470663447 597206517 722902754 849338137

sources
18.270000 37.620000 59.640000 80.390000 101.650000 119.970000 149.680000
107788837 226834624 347229033 469087606 595764669 719374196 842817283

proteins
24.600000 50.380000 80.660000 108.170000 141.550000 167.810000 204.140000
103484312 229733955 353999112 475259394 599355976 709242764 817903353

dblp.xml
18.550000 38.280000 59.090000 78.110000 99.320000 117.810000 140.230000
95245799 200100552 308498854 416999777 528990260 641102313 752168944

Apesar dos tempos de indexação variarem conforme o arquivo de texto, dá pra notar um comportamento quase linear em todos eles, em função do tamanho do texto original: os arquivos de 5MB demoram uma média de 4.3 segundos por MB, enquanto os maiores chegam a uma média de 5.03 segundos por MB.
Já sobre o tamanho do índice gerado, quase todos os arquivos têm resultados semelhantes, exceto pelo dblp.xml, cujos arquivos gerados são ligeiramente menores do que os outros. Os arquivos gerados também apresentam um comportamento linear em função do tamanho do arquivo original. Os arquivos de 5MB geram índices de tamanho, em média, 20.8 vezes maior. Já os de 35MB geram arquivos em média 23.55 vezes maiores.


Consulta
