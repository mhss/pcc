Segundo projeto de PCC

Grupo:
Mário Henrique Santos da Silva (mhss)
	Árvore de sufixo
	Maior parte do front-end
	Scripts de teste
Israel Batista Freitas da Silva (ibfs)
	Array de sufixo
	Algoritmos de compressão
	Testes

Implementação

No modo de indexação, o conteúdo do arquivo é lido, e o conjunto de caracteres dele é determinado. Depois é construída a árvore de sufixo ou array de sufixo, dependendo da escolha do usuário. Então, em um arquivo são escritos o alfabeto e o índice do texto. O índice é representado por uma sequência de inteiros e caracteres, cada um escrito com fibonacci encoding. Então são escritos o tamanho e número de linhas do texto. Por último, o próprio texto é comprimido e escrito no arquivo. O algoritmo de compressão pode ser o LZ77 ou LZ78.
No modo de consulta, o arquivo de índice é aberto e são lidos o alfabeto do texto, o índice e o próprio texto, este último sendo descomprimido. O arquivo de índice informa o algoritmo de compressão usado e se o índice é uma árvore ou array de sufixo. Depois o programa percorre o texto pra determinar as posições de fim de cada linha. Então, para cada padrão a ser buscado, o programa encontra suas ocorrências no índice, determina as linhas às quais cada uma pertence e armazena elas num conjunto. Finalmente, cada linha com ocorrência de pelo menos um padrão é impressa, ou só a quantidade delas.

Algoritmos de Indexação
- Árvore de sufixo
O algoritmo usado para a construção foi o mostrado em aula, Ukkonen de 1995, com algumas alterações. Cada nó explícito da árvore é representado por um struct com um map que guarda as transições que saem daquele nó, indexadas pelo primeiro caractere da aresta. Os nós da árvore são guardados num array. Os suffix links são armazenados fora do struct, em um array alocado dinamicamente, pois são necessários somente durante a construção da árvore.
Os nós implícitos da árvore são representados por um struct com um nó explícito e um intervalo da string. Esse mesmo struct, por conveniência, representa as transições que saem de cada nó.
Para ser escrita num arquivo, a árvore é convertida numa sequência de inteiros e caracteres. O primeiro é a quantidade total de nós, e depois dele vêm, em sequência, as serializações de cada nó. A serialização de um nó consiste da quantidade de transações que saem dele, seguida pela sequência dessas transações. Cada transação é representada pelo índice do nó alvo e o intervalo da string que contém o rótulo da aresta. Cada valor é codificado no arquivo utilizando fibonacci encoding.
Para buscar um padrão, o programa procura o nó explícito mais baixo na árvore cujo rótulo tenha como prefixo o padrão buscado. Se ele existir, para cada folha da subárvore dele, o programa pega a altura e com ela determina a posição da ocorrência correspondente.

- Array de sufixo
O algoritmo utilizado para a construção do array de sufixo foi o Manber & Myers. São utilizados 4 arrays: um para o próprio array de sufixo, um para guardar o rank de cada sufixo, um para realizar o counting sort, e outro temporário que funciona como array de sufixo temporário e rank temporário. O rank inicial é dado pelo valor do caractere no Alfabeto.
As buscas são realizadas através do uso de duas buscas binárias: uma encontra o menor índice i no array de sufixo, a outra encontra o maior índice j no array de sufixo, tal qual, o prefixo de tamanho |P| do sufixo é igual ao padrão procurado, dado que P é o padrão procurado, e |P| representa o tamanho do padrão. O intervalo fechado de i à j possui todos os sufixos que possuem o padrão procurado como prefixo. Todos estes sufixos são processados e as linhas em que eles ocorrem são encontradas e reportadas pelo programa. O custo da busca é O(|P| * log(N)), onde N é o tamanho do texto.

Algoritmos de Compressão
- LZ77
O algoritmo LZ77 implementado foi a versão padrão do algoritmo, com tamanho de 1024 para cada array (dictionary e preview), e utilizando-se o algoritmo Aho-Corasick no preview, para encontrar o maior matching no array dictionary, em tempo linear no tamanho dos arrays.

- LZ78
O algoritmo LZ78, no momento de codificar o texto, utiliza uma estrutura de dados chamada Trie que funcionará como o dicionário necessário ao algoritmo. Esta Trie é implementada através da struct LzNode, declarada no mesmo arquivo do LZ78. No momento de descodificar o texto, é utilizado apenas um array de tamanho dinâmico (std::vector) para realização do processo.


Detalhes

Nos argumentos pra consulta, botamos o padrão depois do texto, pra ficar mais fácil fazer testes.
O programa só aceita textos com caracteres ASCII com valor de 0 a 255.
O consumo de memória durante a indexação tende a ser muito grande, chegando a 3GB para arquivos de mais de 25MB.
O programa só aceita padrões de no máximo 1000 caracteres.
Não conseguimos executar o programa corretamente com textos maiores que 35MB.

Testes

RAEL MUDA AQUI
Os testes da ferramenta foram realizados num computador com processador Intel Core i3 de 2.53GHz com 3.7 GB de memória RAM, com um SO Ubuntu 13.10 de 32 bits.


Medimos o tempo médio gasto para indexar arquivos de texto, bem como o tamanho final dos arquivos gerados. Também medimos o tempo médio gasto com consultas de conjuntos de padrões nos índices dos textos. Procuramos variar o tipo e tamanho dos textos e padrões buscados, algoritmos de compressão e tipos de índices utilizados. O desempenho das consultas do projeto foi comparado com o do programa grep ...

--------------
Os testes da ferramenta foram realizados em uma máquina virtual XUbuntu. A máquina hospedeira possui processador Intel Core i7 de 2.00 GHz, memória de 16GB, com SO Windows 8.1. Já a máquina virtual, possui 8 GB de memória e dois, dos 4 núcleos de processamento.



